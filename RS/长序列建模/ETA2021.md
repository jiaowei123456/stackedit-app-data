# End-to-End User Behavior Retrieval in Click-Through Rate Prediction Model
[原文链接](https://arxiv.org/abs/1708.05123)
## 0 摘要：
点击率预测是推荐系统（RS）中的核心任务之一。它会为每个用户-项目对预测出个性化的点击概率。最近，研究人员发现，通过考虑用户行为序列（尤其是长期用户行为序列），CTR 模型的性能可以得到极大的提升。一份关于某电子商务网站的报告表明，在过去的 5 个月里，有 23%的用户进行了超过 1000 次的点击。尽管有许多研究工作专注于对用户行为序列进行建模，但由于现实世界系统中严格的推理时间限制，很少有工作能够处理长期用户行为序列。为此，提出了两阶段方法以突破性能限制。在第一阶段，设计了一个辅助任务，从长期用户行为序列中检索出前 k 个相似项目。在第二阶段，将经典的注意力机制应用于候选项目和第一阶段中选择的 k 个项目之间。然而，检索阶段和主要的点击率任务之间存在信息差距。这种目标差异会极大地削弱长期用户序列带来的性能提升。在本文中，受 Reformer 的启发，我们提出了一种名为 ETA（End-to-end Target Attention, 端到端目标注意力）的局部敏感哈希方法，该方法能够大幅降低训练和推理成本，并使具有长期用户行为序列的端到端训练成为可能。无论是离线实验还是在线实验都证实了我们模型的有效性。我们将 ETA 应用于一个大规模的真实世界电子商务系统中，并与一个两阶段的长用户序列点击率模型相比，在商品总价值（GMV）方面实现了额外 3.1%的提升。
## 1 论文解决的问题：
* 然而，由于计算和存储资源昂贵，DIN使用最近的50个行为进行目标注意，忽略了长用户行为序列中的资源信息，显然是次优的。
* 
## 2 论文创新点：
* 我们使用 SimHash 为用户行为序列中的每个项目生成一个指纹。然后，利用汉明距离来帮助选择目标关注的前 k 个项目。我们的方法将检索复杂度从 O (L ∗ B ∗ d) 的乘法运算降低到 O (L ∗ B) 的汉明距离计算，其中 L 是行为序列的长度，B 是每次推荐中由 CTR 模型评分的候选项目数量，d 是项目嵌入的维度。复杂度的降低使我们能够去除离线辅助模型，并在训练和服务过程中进行实时检索。

## 3 方法：
![输入图片说明](/imgs/2025-07-18/vALe0H8yIPfTtONK.png)
![输入图片说明](/imgs/2025-07-18/wITSfqKHWGcsdONf.png)
## 4 模型结构与实现代码：
```Python
def Hamming_distance_list(x1, x2):  
    res = 0  
    assert len(x1) == len(x2), 'the length dose not match'  
    for i in range(len(x1)):  
        if x1[i] != x2[i]:  
            res += 1  
    return res  
  
class ETA(nn.Module):  
    def __init__(self, user_num, item_num, hash_size, hidden_size=64, seq_len=100):  
        """  
        ETA input parameters        :param user_num: int numbers of users        :param item_num: int numbers of items        :param hidden_size: embedding_size        :param hash_size: the dimension of hashed vector:param seq_len: length of sub-sequence        """        super(ETA, self).__init__()  
        self.user_num = user_num  
        self.item_num = item_num  
        self.hidden_size = hidden_size  
        self.seq_len = seq_len  
        self.user_embedding = nn.Embedding(user_num, hidden_size)  
        self.item_embedding = nn.Embedding(item_num, hidden_size)  
        self.linear = nn.Sequential(  
            nn.Linear(hidden_size * 4, 80),  
            m.Dice(80),  
            nn.Linear(80, 40),  
            m.Dice(40),  
            nn.Linear(40, 2)  
        )  
        self.au = m.ActivationUnit(hidden_size)  
        self.hashing = nn.Linear(hidden_size, hash_size)  
  
    def forward(self, user, item, long_term, short_term):  
        """  
        :param user: user id        :param item: item id        :param long_term: long-term behavior sequence        :param short_term: short-term behavior sequence        """        user = torch.flatten(self.user_embedding(user))  
        item = torch.flatten(self.item_embedding(item))  
        hashed_item = self.hashing(item)   # 当前物品经过 self.hashing 后的哈希向量  
        long_item = []  
        for i in range(len(long_term)):  
            long_item.append(torch.flatten(self.item_embedding(long_term[i])))  
  
        short_item = []  
        for i in range(len(short_term)):  
            short_item.append(torch.flatten(self.item_embedding(short_term[i])))  
  
        long_item = torch.stack(long_item)  
        short_item = torch.stack(short_item)  
        # 第一阶段开始，求topk个相似的向量  
        heap = []  
        heapq.heapify(heap)    # 构建一个堆heap  
        for i in range(len(long_item)):  
            cur_item = self.hashing(long_item[i])  
            hashed_item, cur_item = torch.relu(torch.sign(hashed_item)), torch.relu(torch.sign(cur_item)) # 求两个向量的hash表示01表示  
            sim = Hamming_distance_list(hashed_item, cur_item)  
            if len(heap) < self.seq_len:      # 选出最相似的seq_len个向量  
                heapq.heappush(heap, (sim, long_item[i]))  
            else:  
                heapq.heappush(heap, (sim, long_item[i]))  
                heapq.heappop(heap)  
  
        topK = heap[:, 1]     # heap(sim, long_item[i])  表示取出所有物品向量    
          
          
# 第二阶段，计算注意力加权的长短序列向量  
        weights = []  
        for i in range(len(topK)):  
            weight = self.au(topK[i], item)  
            weights.append(weight)  
  
        long = torch.zeros_like(topK[0])  
        for i in range(len(topK)):  
            long += torch.tensor(weights[i] * topK[i], dtype=torch.float32)   #输出加权求和的向量  
  
        weights = []  
        for i in range(len(short_item)):  
            weight = self.au(short_item[i], item)  
            weights.append(weight)  
  
        short = torch.zeros_like(short_item[0])  
        for i in range(len(short_item)):  
            short += torch.tensor(weights[i] * short_item[i], dtype=torch.float32)  
  
        res = torch.cat([user, item, long, short], -1)  
        res = self.linear(res)  
        return res
```


## 5 实验与分析：

<!--stackedit_data:
eyJoaXN0b3J5IjpbMTEyMzEyNjk1NSwxNzAzNzQzMDkzXX0=
-->