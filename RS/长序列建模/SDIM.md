# Sampling Is All You Need on Modeling Long-Term User Behaviors for CTR Prediction
[原文链接](https://doi.org/10.1145/3383313.3412236)
## 0 摘要：
丰富的用户行为数据已被证明对点击率（CTR）预测应用具有极大价值，尤其是在工业推荐、搜索或广告系统中。然而，由于在线服务时间的严格要求，现实世界中的系统很难充分利用长期用户行为。大多数先前的工作采用基于检索的策略，即首先检索少量用户行为以供后续关注。然而，基于检索的方法并非最优，会导致信息丢失，并且难以平衡检索算法的有效性和效率。在本文中，我们提出了 SDIM（Sampling-based Deep Interest Modeling，基于采样的深度兴趣建模），这是一种简单而有效的基于采样的端到端方法，用于建模长期用户行为。我们从多个哈希函数中采样，生成候选项目和用户行为序列中每个项目的哈希签名，并通过直接收集与候选项目具有相同哈希签名的行为项目来获取用户兴趣。我们从理论和实验两方面证明，所提出的方法在对长期用户行为建模方面与标准的基于注意力的模型表现相当，但速度要快很多。我们还介绍了在系统中部署 SDIM 的情况。具体来说，我们通过设计一个名为 BSE（行为序列编码）的独立模块，将最耗时的行为序列哈希与 CTR 模型分离。BSE 对 CTR 服务器来说是无延迟的，这使我们能够对极长的用户行为进行建模。我们进行了离线和在线实验来证明 SDIM 的有效性。SDIM 现已部署在美团 APP 的搜索系统中。

## 背景
阿里巴巴提出的 MIMN[8] 就是其中的一个典型成果，它通过学习算法和服务系统的协同设计实现了最先进的水平。MIMN 是首个能够以长度扩展至 1000 的方式对序列用户行为数据进行建模的工业解决方案。具体而言，**MIMN 逐步将一个用户的多种兴趣嵌入到一个固定大小的记忆矩阵中，该矩阵会随着每次新的行为而更新**。这样一来，用户建模的计算过程就与点击率预测相分离。因此，在在线服务中，延迟不会成为问题，而存储成本则取决于记忆矩阵的大小，这远小于原始的行为序列。类似的想法也可以在长期兴趣建模中找到。然而，基于记忆网络的方法仍然难以对任意长的序列数据进行建模。实际上，我们发现，当用户行为序列的长度进一步增加，比如达到 10000 或更多时，MIMN 无法准确捕捉给定候选项目的用户兴趣。这是**因为将所有用户的过往行为都编码进一个固定大小的内存矩阵中，会导致大量的噪声被包含在内存单元中**。

## 1 论文解决的问题：


## 2 论文创新点：
* 为应对这些挑战，我们采用了如图 1 所示的两阶段框架。具体而言，在预训练阶段，我们提出了语义感知对比学习（SCL）方法。在这个阶段，我们利用用户的搜索查询和随后的购买行为来构建具有语义相似性的样本对，捕捉到在电子商务场景中对用户最为重要的语义相似性的维度。对于负样本，我们从一个大型记忆库中获取。SCL 方法使多模态表示能够有效地衡量项目之间的语义相似性。
* 在获得高质量的多模态表示后，我们提出了两种方法将这些表示融入现有的基于 ID 的模型中。首先，我们开发了一种名为 SimTier 的方法，用于**衡量目标项与用户之前交互过的项之间的相似度**。然后，生成的 SimTier 向量与其他嵌入一起被连接起来，并输入到后续层中。此外，为了解决多模态表示和 ID 嵌入在训练轮数上的差异问题，我们引入了多模态知识提取器（MAKE）模块。MAKE 模块将与多模态表示相关的参数优化与之分离。这些属于基于身份的模型，能够使与多模态表示相关的参数实现更有效的学习。

### 2.1 预训练数据集的构建：
在电子商务的背景下，用户的搜索查询以及随后的购买行为往往表明该查询与所购商品之间存在很强的语义相似性。例如，如果用户搜索一张枕头的图片，然后购买了一款枕头，那么这一系列操作就表明这两张图片（查询到的图片和所购买物品的图片）在语义上足够相似，能够满足用户的购买意愿。因此，如表 1 所示，在训练文本编码器时，我们将用户搜索查询的文本与他们最终购买的商品的标题作为语义相似对进行配对。同样，对于图像模式，用户从淘宝的图片搜索场景中获得的图片查询与后续购买的商品的图片进行配对。这种配对策略自然地捕捉到了与电子商务场景中用户最为相关的语义相似性的维度，反映了影响他们购买决策的因素。

对于每一对语义相似的样本，我们将当前批次中的所有其他样本视为潜在的不相似样本，这可以通过将当前批次中的样本用作负样本来实现。为了进一步提高模型的性能，我们旨在增加训练期间可用的负样本数量。具体而言，我们从 MoCo [12] 中获得灵感，并采用了使用动量更新模型的技术，从而能够从更大的记忆库中更有效地抽取更多负样本。关于构建负样本对的更复杂策略，例如识别困难负样本 [23]，将在第 6.1.2 节中详细阐述。

### 2.1 技巧：
* 将多模态表示直接整合到基于 ID 的模型中并不能达到最佳性能，这一点在第 6.3 节中有更详细的说明。出现这一问题的原因在于，与多模态表示相关的参数，例如与多模态表示相连的多层感知机的参数，在与 ID 嵌入进行联合训练的过程中并未得到充分学习[29]。相比之下，简化多模态表示使用方式的策略，例如将其转换为语义 ID（从而用 ID 来表示嵌入向量）[26， 29]，似乎能带来更好的性能。
* 我们发现，利用多模态数据的模型通过在同一个数据集上进行多个周期的训练而受益，其性能随着训练周期的增加而显著提升。相比之下，基于身份的模型则存在一周期过拟合现象，即在第二个周期开始时模型性能会急剧下降[33]。这一结果表明，与多模态表示相关的参数需要更多的周期才能正确收敛，这与基于身份的模型的行为形成了对比。因此，当将多模态表示纳入基于身份的模型并仅训练一个周期时，存在多模态相关参数可能未得到充分训练的风险

## 4 模型结构与实现代码：
### 4.1 SimTier：
观察 1 呼吁简化多模态表示的使用方式。为此，我们提出了一种简单但有效的方法——SimTier。如图 2（a）所示，SimTier 从计算目标候选项的多模态表示（记为 vc）与其它元素之间的点积相似度开始。在计算出相似度分数后，我们将分数范围[-1.0, 1.0]划分为 N 个预定义的层级。在每个层级内，我们统计落入该对应范围内的相似度分数的数量。因此，我们得到一个 N 维向量，每个维度代表对应层级中的相似度分数的数量。这样，SimTier 就有效地将一组高维多模态表示转换为一个 N 维向量，该向量封装了目标项与用户历史交互之间的相似度程度。然后，将获得的 N 维向量与其他嵌入向量连接起来，并输入到后续的多层感知机（MLP）中。我们在算法 1 中提供了 SimTier 的伪代码。

## 5 实验与分析：

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTUzOTM3OTcxMCwtMTcyNzMzMDQ5MiwtMT
E2ODAxMjM2M119
-->