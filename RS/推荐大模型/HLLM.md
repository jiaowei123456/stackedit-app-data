# HLLM:Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling
[原文链接]([2409.12740](https://arxiv.org/pdf/2409.12740))
## 0 摘要：


## 背景


## 1 论文解决的问题：
尽管这些技术有所进步，但将语言模型与推荐系统相结合在复杂性和有效性方面仍面临显著挑战。
* 其中一个问题是，将用户的使用历史行为序列以文本形式输入到语言模型中会导致输入序列非常长。因此，**LLM需要比基于 ID-emb的方法更长的序列来表示相同时间段内的用户行为**，而语言模型中的自注意力模块的复杂性会随着序列长度的增加而呈平方级增长。
* 此外，**推荐单个项目需要生成多个文本标记，这会导致多次前向传递**，从而降低效率。在有效性方面，现有的基于语言模型的方法相较于传统方法在性能上的提升并不显著，这引发了关于语言模型潜力是否已得到充分释放的疑问。

## 2 论文创新点：
为解决这些挑战，本文提出了“分层大型语言模型（HLLM）”架构。该方法首先使用大型语言模型（LLM）来提取项目特征。为了使 LLM 能够有效地提取这些特征，会在每个项目的详细文本描述末尾添加一个特殊的标记。然后将这个增强后的描述输入到 LLM 中（称为“item  LLM”），对应于该特殊标记的输出被用作item特征。这些item特征随后被输入到第二个 LLM（称为“user  LLM”）中，以模拟用户兴趣并预测未来行为。**通过将大量的项目描述转换为简洁的嵌入，行为序列的长度被缩短到基于 ID 的模型的长度，与其他基于文本的 LLM 推荐模型相比，显著降低了计算复杂度。**我们还验证了 HLLM 比基于 ID 的模型具有显著的训练效率优势，因为它仅用少量的训练数据就能超越基于 ID 的模型。
我们进行了大量的实验来探究预训练的价值。尽管 HLLM 并未像标准 LLM 那样以常规方式进行文本交互，例如项目 LLM 被设计为特征提取器，而用户 LLM 的输入和输出均为项目嵌入，但预训练的权重对于这两种类型的 LLM 都证明是有益的。这表明 LLM 中嵌入的世界知识确实对推荐具有价值。然而，这并不排除对推荐目标进行微调的必要性。相反，我们的实验表明，这种微调对于超越传统方法至关重要。为了验证可扩展性，对大型学术数据集的实验表明，LLM 具有出色的可扩展性，随着模型参数的增加，性能会不断提高。在有限的资源范围内，参数多达 70 亿的模型在规模增加时表现出持续的性能提升。

### 2.1 预训练数据集的构建：


### 2.1 技巧：


## 4 模型结构与实现代码：


## 5 实验与分析：

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIxMzAwMDA3MDAsNDg3NjkxMTE2XX0=
-->