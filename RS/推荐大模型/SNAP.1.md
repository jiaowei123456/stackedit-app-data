# Generative Recommendation with Semantic IDs: A Practitioner’s Handbook
[原文链接]()
## 0 摘要：
生成式推荐（GR）因其相较于传统模型表现出的出色性能而备受关注。GR 成功的关键因素之一是语义ID（SID），它将连续的语义表示（例如来自大型语言模型的表示）转换为离散的标识符序列。这使得带有 SID 的 GR 模型既能整合语义信息，又能学习协同过滤信号，同时还能保留离散解码的优点。然而，现有文献中各种不同的建模技术、超参数和实验设置使得直接比较 GR 提案变得具有挑战性。此外，缺乏一个开源的统一框架阻碍了系统的基准测试和扩展，减缓了模型迭代的速度。为了解决这一挑战，我们的工作引入并开源了一个带有语义标识符的生成式推荐框架，即 GRID，专门设计以实现模块化，以便于轻松更换组件并加速想法的迭代。使用 GRID，我们系统地在公共基准测试上对带有 SID 的 GR 模型的不同组件进行实验和消融研究。我们对 GRID 的全面实验表明，在具有 SIDs 的 GR 模型中，许多被忽视的架构组件对性能有着显著的影响。这不仅提供了新的见解，还验证了开源平台在进行稳健的基准测试和推进 GR 研究方面的重要作用。GRID 已开源，访问地址为 https://github.com/snap-research/GRID 。

## 背景
在生成推荐系统（GR）中，有一种流行的范式是利用语义ID（SIDs）[7, 44, 61] 来弥合预训练基础模型与推荐系统的差距。如图 1 所示，该范式首先利用一种模态编码器和一种量化分词器（例如 RQ-VAE [31]、VQ-VAE [10] 或残差 K 均值 [7]）将模态特征（例如图像或文本）转换为 SIDs。然后，一个序列推荐器被训练来根据用户过去所选择的 SIDs 自回归地预测用户未来将交互的项目的 SIDs。
带有sid的GR提供了一种有效的方法来利用：
 1. 预先训练的基础模型中编码的语义知识
 2. 在用户-项目交互历史中的协同信号编码
 3. 这里是列表文本

两个Item在SID上的重叠部分原则上反映了它们的语义相似性，而后续Item有监督的使GR模型能够学习跨越SID的协同信号。
经典论文：Onerec、Text2Tracks、LIGER等

## 1 论文解决的问题：
首先，大多数相关文献并未提供开源实现。这一挑战使得从业者和研究人员不得不承担复杂的重新实现负担，这不仅需要高超的技术专长，还需要仔细的超参数调整。正如我们在本文后面将展示的那样，GR 流程的良好性能通常由多个相互影响的因素共同决定（例如，适当的训练策略和仔细的架构调整）。
从零开始构建带有 SIDs 的 GR 流程时，调试和确定潜在性能不佳的根本原因极其困难，这会显著减缓研究和开发的速度。
此外，关于使用 SIDs 的 GR 的设计选择的有用见解在文献中通常没有得到充分讨论，这使得从业者不得不花费宝贵的时间和计算资源来构建自己的实验流程，以便自行发展这些理解。为弥合这些差距，我们做出了以下贡献：

## 2 论文创新点：


### 2.1 预训练数据集的构建：


### 2.1 技巧：


## 4 模型结构与实现代码：


## 5 实验与分析：

<!--stackedit_data:
eyJoaXN0b3J5IjpbNzM5NDc4NDM5LC0xOTM2NDY5OTgsLTY3OD
MxNjg2Nl19
-->